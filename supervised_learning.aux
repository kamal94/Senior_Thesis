\relax 
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Supervised Learning}{13}}
\newlabel{sec:supervised_learning}{{\unhbox \voidb@x \hbox {IV-B}}{13}}
\newlabel{sec:perceptron}{{\unhbox \voidb@x \hbox {IV-B}1}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}1}Perceptron}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Two sets of data, one of which is linearly separable (Left) and the other is non linearly separable (Right). Linear separability means that a line can be found that can perfectly segregate the two classes into two sections. A diagonal, horizontal, or vertical line between the blue and red points can be drawn on the left that achieves that goal. However, on the right there is no one line that can be used to separate the red from blue points. This problem of finding a line of separation between two linearly separable data sets can be solved by using a binary classifier, the earliest example of which is the perceptron.\relax }}{14}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:two_classes_example}{{1}{14}}
\citation{minsky1969perceptrons}
\citation{Yadav2015}
\newlabel{eq:piecewise_threshold_function}{{2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The perceptron model can be used to solve binary classification in linearly separable datasets as in the left image. After training, all points below the shown line of separation would be classified as -1, and all points above the line would be classified as +1. Seemingly, this behavior would correctly extrapolate to unseen data points from a similar distribution. In the case of non linearly separable datasets, the perceptron keeps adjusting its weights but never reaches a solution which correctly classifies all data inputs, meaning the model quits after a set limit of iterations through the dataset. This results in a having a line that clearly does not separate the two classes (Right).\relax }}{15}}
\newlabel{fig:perceptron_solution}{{2}{15}}
\newlabel{sec:neural_networks}{{\unhbox \voidb@x \hbox {IV-B}2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}2}Neural Networks}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Different activation functions can be applied to the perceptron model. The simplest and earliest activation function is the step function (Left) which outputs either a $+1$ or $-1$. A disadvantage of the step function is that small changes in the weighted sum ($S$) could cause a large change in the output ($\kappa $). This is solved by the sigmoid activation function (right) which gives a output (between $0$ and $+1$) that is proportional to $\S  $ within a given range. When a perceptron implements a sigmoid activation unit, it is referred to as a sigmoid learning unit.\relax }}{17}}
\newlabel{fig:activation_functions}{{3}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Perceptrons linked in networks with different topologies. Yellow represents input notes, gray represents hidden nodes, and green represents output nodes. The left network contains only one layer, the input layer, with its associated weights that feed into the output layer. This network essentially simulates a computation that is equivalent to the perceptron model. The center network contains a hidden layer composed of simply 1 node. This network can solve the XOR problem, and is able to solve the linearly inseparable dataset in Fig 1\hbox {}. The more nodes added to the hidden layer and the more hidden layers there are, the more communication happens between the nodes in the previous layer, and therefore the higher the abstraction. The network on the right is a more dense network with two hidden layers and many more hidden nodes.\relax }}{17}}
\newlabel{fig:perceptron_layers_example}{{4}{17}}
\newlabel{eq:gradient_descent_on_sigma}{{5}{18}}
\newlabel{eq:sigma_derivative}{{6}{18}}
\newlabel{eq:update_rule_for_sigma}{{7}{18}}
\citation{mitchell1997machine}
\citation{mitchell1997machine}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Back propagation works by minimizing the error function using gradient descent. In this case, the error function is the MSE, and its partial derivative with respect to each weight from the $i$th node in the previous layer is $2w_ix_i(\lambda - \kappa _t$ where $\lambda $ is the desired outcome and $\kappa _t$ is the predicted outcome at iteration $t$. In each iteration, applying gradient descent results in a move towards the opposite of the gradient, meaning partial derivative of the error with respect to that weight is negated from the weight (right). This method is guaranteed to converge, however slowly, over well defined continuous activation functions, an example of which is the sigmoid function (Fig. 3\hbox {}).\relax }}{19}}
\newlabel{fig:back_propagation}{{5}{19}}
\newlabel{sec:decision_trees}{{\unhbox \voidb@x \hbox {IV-B}3}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}3}Decision Trees}{19}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Weather and Tennis court dataset example \cite  {mitchell1997machine}. All features are categorical, meaning the values of the features are from a finite, relatively small set of possibilities. The values can not be numerically represented in a formula or compared, nor do they represent values on a range.\relax }}{20}}
\newlabel{table:categorial_examples_weather}{{I}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The decisions to play or not play tennis when the decision is split on wind conditions. Red balls represent No and green balls represent Yes. As we can tell from this graph, splitting on the Windy feature does not provide a homogeneous set (both sides of the split are not purely green or purely red). This means that we can't conclude that whenever the wind is strong tennis can not be played, vise versa. However, It seems that the split caused us to see a relationship between wind conditions and playing tennis, since when the wind was weak most decisions were to play tennis, while when it was windy most decisions were not to play tennis.\relax }}{20}}
\newlabel{fig:split_on_wind}{{6}{20}}
\citation{mitchell1997machine}
\citation{mitchell1997machine}
\newlabel{sec:regression_supervised_learning}{{\unhbox \voidb@x \hbox {IV-B}4}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}4}Regression Prediction}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The entropy of a system with two decisions each of which have a fraction $p_1$ and $p_2$ (fraction $p_2$ is not shown here because it is simply $1-p_1$). When the system has both fractions in equal proportions, it is perfectly heterogeneous, so it has the highest entropy measure of $1$. On the other end, when one fraction dominates the system, the entropy goes to $0$. In this way, entropy measures how "polluted" or pure a system is, giving a higher score to disorganized, polluted systems, and a lower score to homogeneous, pure systems.\relax }}{23}}
\newlabel{fig:entropy_two_decisions}{{7}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A decision tree that can be generated by iterating over the tennis-weather dataset using the information gain equation. This is taken from Michel's book on Machine Learning \cite  {mitchell1997machine}.\relax }}{23}}
\newlabel{fig:decision_tree_for_tennis}{{8}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A Decision Tree trained on a dataset of simple square functions, where the inputs were numbers from 0 to 10 and output is the square of each number. The tree shows a jagged approximation of the square function between 0 and 10, which indicates some level of learning. However, the tree shows very poor generalization outside the learning range. When tested on input that is below 0, the tree matches to the closest label in the decision boundary, which is "0". A similar decision is made for input that is greater than 10, where the trees matches all numbers greater than 10 to the label of 10 ("100").\relax }}{24}}
\newlabel{fig:decision_tree_regression_and_classification}{{9}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Different lines of fit and their errors (dashed and dotted lines) with respect to the noisy input data. Because $g(x)$ and $h(x)$ have larger error lines than $f(x)$, $f(x)$ is the best fit for the data out of the three drawn lines. Note that for $f(x)$, the negative and positive errors cancel out, leading to a sum of error of $-21$. This is allayed by suming the square of the erro instead, which results in a minimizable equation that evaluates to $176$.\relax }}{25}}
\newlabel{fig:error_lines}{{10}{25}}
\citation{Finney1996}
\newlabel{eq:least_square}{{10}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Finding line of least squared error for data with an exponential trend. First, the datapoints (Left) are transformed to their logs (Center). Then a line of best fit is found through linear regression (Center). The line is then transformed back to the original space by applying the exponential function (Right).\relax }}{26}}
\newlabel{fig:log_regression}{{11}{26}}
\@setckpt{supervised_learning}{
\setcounter{page}{27}
\setcounter{equation}{11}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{section}{4}
\setcounter{subsection}{2}
\setcounter{subsubsection}{4}
\setcounter{paragraph}{0}
\setcounter{IEEEsubequation}{0}
\setcounter{figure}{11}
\setcounter{table}{1}
\setcounter{IEEEbiography}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{1}
\setcounter{ALG@blocknr}{1}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
}
