\section{Machine Learning}
Machine learning is a buzz word that most computer scientists---and indeed most people in STEM fields---hear around, but only a few have had proper introduction into what exactly the field of machine learning studied, what it aims to accomplish, and how much success there has been in the field (measured in terms of application to industry). In a nutshell, machine learning is the study of developing algorithms that can solve problems on their own without being explicitly told how to solve them or what directions to follow to reach a conclusion. This might seems anti-intuitive so some computer scientists, after all programming---a task most computer scientists perform on daily basis---is literally the process of telling a computer exactly what you want it to do. However, there are some problems and tasks in which humans \textit{can understand} how to perform, but simply \textit{can not explain} how to perform them, at least not in binary code. For example, teaching a child how to identify the number $3$ is an intuitive task: a three is a three if it has two moon-like or semicircle shapes on top of one another. However, programming a computer to recognize a three is a completely different task, because you would have to write an algorithm to detect a semi-circle in pixels, and then you would have to tell it to account for two such shapes. But what if the semicircles are not joined? or if the semicircles were not curvy enough? or if the top part of the three was a straight line, a common font type? or what if the three is written in a small font or a big font? A programmer would have to account for all these possibilities with if statements, and that is only for the number 3. When extended to a whole alphabet, the scale of this problem becomes too large for one program to be written. Machine Learning offers a simple solution for such tedious if not impossible problems: show the computer many 3's and many non-3's and let \textit{it} decide what logical statements to take and when. 

In a sense, this is inspired by how humans learn: we are put in situations where we read the same letters over and over again, associating them with sounds and concepts. Over enough period of time, we \textit{learn}, mostly by forming associations with our experiences. Machine learning attempts to mimic that natural phenomenon with algorithms that attempt to do everything by doing very little, succeeding at times and failing in others. This section is an overview of the field of supervised machine learning, its history, and a few algorithms that form the baseline education on the field.


\subsection{History of Machine Learning}
The first sight of ML is attributed to Arthur Samuel who, in 1952, wrote the first learning computer checkers game. This game learned by playing against itself and against other human players in a supervised setting \cite{britanica1i2016}. After multiple enhancements throughout the years, this program was able to beat novice checker players, demonstrating the potential power of ML. The same basic principles used by Samuel's program more than 60 years ago are still being used (with more optimized algorithms on greatly more powerful computers) today at Deep Brain, beating humans at more and more board games (See alpha Go).

While Dr. Sameul was working on his checkers game at IBM, a major development was happening at College of Medicine at the University of Illinois. There, Warren McCulloch and Walter Pitts proposed the first mathematical model of what they believed to be the structural unit of the brain: the neuron. In their paper \textit{A Logical Calculus of The Ideas Immanent IN Nervous Activity} published in 1943, they described the brain as a network of neurons in which each neuron had excitetory and inhibitory input and with each of these inputs came a weight to imply its importance \cite{mcculloch1943logical}. Each neruon in the brain had a certain threshold which represented its reluctance to "fire." If the weighted sum of all its excitetory and inhibitory inputs was greater than the threshold, then the neuron would fire. Otherwise, it would not. This was coined as the "all or none" behavior (Fig. \ref{fig:activation_functions}).

Mathematically, the model describes a set of inputs $X = x_0, x_1, \dots, x_n$, a corresponding set of weights $W = w_0, w_1, \dots, w_n$, and a threshold $\theta$ the output of the neuron is described as the function
\[
f(X,W)=
\begin{cases}
1 &\text{if } \sum_{i=0}^n x_iw_i \geq \theta,\\
0 &\text{Otherwise.}
\end{cases}
\]

For the neuroscience field, the McCollough-Pitts model was a mathematical breakthrough that many have been waiting for to accurately model neurons and the brain. However, the importance of the McCollough-Pitts model to the machine learning field was in that it laid the ground work one of the most important building blocks of today's Artificial Neural Networks: The Perceptron. In 1958 and at the Cornell Aeronautical Laboratory in Buffalo, New York, Frank Rosenblatt introduced this mathematical model that was very similary to the McCollough-Pitts neuron, but had one major difference which was that it had a learning rule that allowed it to adjust the weights of the neurons that feed it. This allowed the perceptron to accept new input as a series of node inputs and adjust the weights of each of these nodes in such a way that allowed the output of the neuron to be consistent with the true label of the input. This was the first sight of an algorithm that can find classification solutions for linearly separble problems (See section \ref{sec:label_classification}). However, there was one big glaring limitation to the perceptron model: it did not handled complex problems. For example, the perceptron model can only learn linearly separable functions (Fig. \ref{ig:perceptron_solution}). This limitation was laid out at length in a scathing critique of the perceptron model in \textit{Perceptrons} written by Minsky and Papert in 1969, which led to a decade-long hiatus in the field of neural-based machine learning algorithms. 

After a few critical papers were published on the ways that perceptrons (referred to as learning units as the field continued to grow) could be connected in different layers to solve previously unsolvable problems, the field was revived and work on what then became known as \textit{neural networks} rose into popularity. However, it was not until the early 2000's that neural networks truly experienced a period of renaissance with many of the applications for neural networks being incorporated into real-life projects like search (e.g. Google, Yahoo, Bing), facial recognition (e.g. Facebook Photos, Google Photos), and human sound understanding (e.g. Siri, Google, Cortana).

