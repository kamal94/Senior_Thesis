\relax 
\@input{introdution.aux}
\citation{practicalDefEpi2014}
\citation{Epilepsy.com.NewTerms}
\@writefile{toc}{\contentsline {section}{\numberline {II}Epilepsy}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Definition}{7}}
\citation{Epilepsy.com.stats}
\citation{Allers2015}
\citation{vivas2012health}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Syndrome}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Epilepsy in Numbers and Life}{8}}
\citation{AEDsideeffects}
\citation{Epilepsy.com.surgery}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Treatment}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-D}1}Medication}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-D}2}Surgery}{9}}
\citation{bailey2005use}
\citation{baranano2008ketogenic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-D}3}Diet}{10}}
\citation{britanica1i2016}
\@writefile{toc}{\contentsline {section}{\numberline {III}Machine Learning}{11}}
\citation{mcculloch1943logical}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}History of Machine Learning}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Supervised Learning}{13}}
\newlabel{sec:supervised_learning}{{\unhbox \voidb@x \hbox {III-B}}{13}}
\newlabel{sec:perceptron}{{\unhbox \voidb@x \hbox {III-B}1}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-B}1}Perceptron}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Two sets of data, one of which is linearly separable (Left) and the other is non linearly separable (Right). Linear separability means that a line can be found that can perfectly segregate the two classes into two sections. A diagonal, horizontal, or vertical line between the blue and red points can be drawn on the left that achieves that goal. However, on the right there is no one line that can be used to separate the red from blue points. This problem of finding a line of separation between two linearly separable data sets can be solved by using a binary classifier, the earliest example of which is the perceptron.\relax }}{14}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:two_classes_example}{{1}{14}}
\citation{minsky1969perceptrons}
\citation{Yadav2015}
\newlabel{eq:piecewise_threshold_function}{{2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The perceptron model can be used to solve binary classification in linearly separable datasets as in the left image. After training, all points below the shown line of separation would be classified as -1, and all points above the line would be classified as +1. Seemingly, this behavior would correctly extrapolate to unseen data points from a similar distribution. In the case of non linearly separable datasets, the perceptron keeps adjusting its weights but never reaches a solution which correctly classifies all data inputs, meaning the model quits after a set limit of iterations through the dataset. This results in a having a line that clearly does not separate the two classes (Right).\relax }}{16}}
\newlabel{fig:perceptron_solution}{{2}{16}}
\newlabel{sec:neural_networks}{{\unhbox \voidb@x \hbox {III-B}2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-B}2}Neural Networks}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Different activation functions can be applied to the perceptron model. The simplest and earliest activation function is the step function (Left) which outputs either a $+1$ or $-1$. A disadvantage of the step function is that small changes in the weighted sum ($S$) could cause a large change in the output ($\kappa $). This is solved by the sigmoid activation function (right) which gives a output (between $0$ and $+1$) that is proportional to $\S  $ within a given range. When a perceptron implements a sigmoid activation unit, it is referred to as a sigmoid learning unit.\relax }}{17}}
\newlabel{fig:activation_functions}{{3}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Perceptrons linked in networks with different topologies. Yellow represents input notes, gray represents hidden nodes, and green represents output nodes. The left network contains only one layer, the input layer, with its associated weights that feed into the output layer. This network essentially simulates a computation that is equivalent to the perceptron model. The center network contains a hidden layer composed of simply 1 node. This network can solve the XOR problem, and is able to solve the linearly inseparable dataset in Fig 1\hbox {}. The more nodes added to the hidden layer and the more hidden layers there are, the more communication happens between the nodes in the previous layer, and therefore the higher the abstraction. The network on the right is a more dense network with two hidden layers and many more hidden nodes.\relax }}{18}}
\newlabel{fig:perceptron_layers_example}{{4}{18}}
\citation{mitchell1997machine}
\citation{mitchell1997machine}
\newlabel{eq:gradient_descent_on_sigma}{{5}{19}}
\newlabel{eq:sigma_derivative}{{6}{19}}
\newlabel{eq:update_rule_for_sigma}{{7}{19}}
\newlabel{sec:decision_trees}{{\unhbox \voidb@x \hbox {III-B}3}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-B}3}Decision Trees}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Back propagation works by minimizing the error function using gradient descent. In this case, the error function is the MSE, and its partial derivative with respect to each weight from the $i$th node in the previous layer is $2w_ix_i(\lambda - \kappa _t$ where $\lambda $ is the desired outcome and $\kappa _t$ is the predicted outcome at iteration $t$. In each iteration, applying gradient descent results in a move towards the opposite of the gradient, meaning partial derivative of the error with respect to that weight is negated from the weight (right). This method is guaranteed to converge, however slowly, over well defined continuous activation functions, an example of which is the sigmoid function (Fig. 3\hbox {}).\relax }}{20}}
\newlabel{fig:back_propagation}{{5}{20}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Weather and Tennis court dataset example \cite  {mitchell1997machine}. All features are categorical, meaning the values of the features are from a finite, relatively small set of possibilities. The values can not be numerically represented in a formula or compared, nor do they represent values on a range.\relax }}{21}}
\newlabel{table:categorial_examples_weather}{{I}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The decisions to play or not play tennis when the decision is split on wind conditions. Red balls represent No and green balls represent Yes. As we can tell from this graph, splitting on the Wind feature does not provide a homogeneous set (both sides of the split are not purely green or purely red). This means that we can't conclude that whenever the wind is strong tennis can not be played, vise versa. However, It seems that the split caused us to see a relationship between wind conditions and playing tennis, since when the wind was weak most decisions were to play tennis, while when it was wind most decisions were not to play tennis.\relax }}{21}}
\newlabel{fig:split_on_wind}{{6}{21}}
\citation{mitchell1997machine}
\citation{mitchell1997machine}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The entropy of a system with two decisions each of which have a fraction $p_1$ and $p_2$ (fraction $p_2$ is not shown here because it is simply $1-p_1$). When the system has both fractions in equal proportions, it is perfectly heterogeneous, so it has the highest entropy measure of $1$. On the other end, when one fraction dominates the system, the entropy goes to $0$. In this way, entropy measures how "polluted" or pure a system is, giving a higher score to disorganized, polluted systems, and a lower score to homogeneous, pure systems.\relax }}{23}}
\newlabel{fig:entropy_two_decisions}{{7}{23}}
\newlabel{sec:regression_supervised_learning}{{\unhbox \voidb@x \hbox {III-B}4}{23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-B}4}Regression Prediction}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A decision tree that can be generated by iterating over the tennis-weather dataset using the information gain equation. This is taken from Michel's book on Machine Learning \cite  {mitchell1997machine}.\relax }}{24}}
\newlabel{fig:decision_tree_for_tennis}{{8}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A Decision Tree trained on a dataset of simple square functions, where the inputs were numbers from 0 to 10 and output is the square of each number. The tree shows a jagged approximation of the square function between 0 and 10, which indicates some level of learning. However, the tree shows very poor generalization outside the learning range. When tested on input that is below 0, the tree matches to the closest label in the decision boundary, which is "0". A similar decision is made for input that is greater than 10, where the trees matches all numbers greater than 10 to the label of 10 ("100").\relax }}{25}}
\newlabel{fig:decision_tree_regression_and_classification}{{9}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Different lines of fit and their errors (dashed and dotted lines) with respect to the noisy input data. Because $g(x)$ and $h(x)$ have larger error lines than $f(x)$, $f(x)$ is the best fit for the data out of the three drawn lines. Note that for $f(x)$, the negative and positive errors cancel out, leading to a sum of error of $-21$. This is allayed by summing the square of the error instead, which results in an equation that can be minimized to $176$.\relax }}{26}}
\newlabel{fig:error_lines}{{10}{26}}
\newlabel{eq:least_square}{{10}{26}}
\citation{Finney1996}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Finding line of least squared error for data with an exponential trend. First, the data points (Left) are transformed to their logs (Center). Then a line of best fit is found through linear regression (Center). The line is then transformed back to the original space by applying the exponential function (Right).\relax }}{27}}
\newlabel{fig:log_regression}{{11}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Unsupervised Learning}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Using a non-linear regression model for the same data set used on in Figure 9\hbox {}, we are able to build a model that correctly extrapolates to unseen numeric data. Since this is one of the requirements for problems with outputs being continuous numbers, thsi model is highly valuable for prediction in such output spaces.\relax }}{28}}
\newlabel{fig:regression_on_square_function}{{12}{28}}
\@input{Sugihara.aux}
\citation{hjornevik2007}
\citation{paxinos2009}
\citation{hjornevik2007}
\citation{paxinos2009}
\@writefile{toc}{\contentsline {section}{\numberline {V}Problem Statement}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Methods}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Data Collection}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces (a) A composite drawing showing the brain in the scull. The 3D reconstruction of the brain has been made using the maps of the Paxinos atlas, and the localization of cortical areas are indicated by different colors. White points indicate the position of the recording sites of the membrane electrode. Names for the cortical areas are also shown (based on Hjornevik \textit  {et al.} and Paxinos \textit  {et al.} \cite  {hjornevik2007} \cite  {paxinos2009}). (b) Photograph of a membrane electrode shows the construction on the top, the numbering (bottom right) and the surgical implantation (bottom left) is also shown. Electrode 1 malfunctioned during recording.\relax }}{36}}
\newlabel{fig:rat_experiment}{{16}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Sample data from electrode 1, in both its raw form and then in its form after kCSD transformation. Applying kernel Current Source Density extracts the true relationship of neural activity, and in theory eliminates disturbances that might be caused by signal interference. Three sample blue lines are drawn to demonstrate the sliding windows that were used to calculate Sugihara Causality between brain regions. In each time window, the causality was calculated between each brain region, and the time window was moved by an amount \textit  {time step}. Different configurations were used for the time window and time step, as reported in table II\hbox {}. Here, the configuration shown has time window as $200$ and time step as $50$.\relax }}{37}}
\newlabel{fig:example_eeg_and_kcsd}{{17}{37}}
\citation{Potworowski2012}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Configurations used for the sliding window when calculating Sugihara causality that was used as a measure of brain communication. These configurations inform our model of the granularity of brain communication. Since we do not know exactly how quickly information is being passed down from region to region, arbitrary choices were made to test how well each performs and make a more informed decision in future research. Because we have different time steps, there are a different number of graphs (data points) in each dataset.\relax }}{38}}
\newlabel{tab:sliding_window_configuration}{{II}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Data Preprocessing}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Sugihara Causality Measurement}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The distribution and lumping of the brain regions in the brain. A total of 12 region channels were constructed from the initial 31 local channels. The schematic is based on rat brain atlas mapping.\relax }}{39}}
\newlabel{fig:brain_region_lumping}{{18}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Sample graph constructed from calculating the Sugihara causality between brain regions. Lumped brain regions correspond to the gray circular mapping in Fig. 18\hbox {}. Edge colors represent the strength of the causal relationship. From weakest to strongest: Yellow, Green, Blue, Red. The edge weight ranges from 0 to 1.\relax }}{39}}
\newlabel{fig:sample_graph}{{19}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-D}}Data Exploration and Visualization}{39}}
\newlabel{fig:sample_pair_causality_plot}{{20a}{40}}
\newlabel{sub@fig:sample_pair_causality_plot}{{a}{40}}
\newlabel{fig:rho_hist_all_experiment}{{20b}{40}}
\newlabel{sub@fig:rho_hist_all_experiment}{{b}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces (a) A sample graph plotting the convergent cross mapping skill ($\rho $) between region (nodes) 1 and 2 during the first 200 ms of the experiment. The skill mapping channel 1 to channel 2 is very similar to the one mapping channel 2 to channel 1. This might infer either bidirectional causality or unidirectional forcing. A similar pattern (close $\rho $ value between pairs) was found for most of the pairs of edges. (b) The distribution of CCM skill ($\rho $) during the entire experiment. Many relationships appear to be causal in the brain, with equally as many being non-causal throughout the experiment. Causality was calculated from signals of lumped regions after calculating the CSD. Cross mapping was done on every pair of regions with library size of 80, and each pair has two causality directions. Sliding windows of 200 ms were used, with a sliding step of 50 ms.\relax }}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Difference of causality values within a pair is small, even when accounting for non-existing relationships where both causalities are below 0.2. This similarity between directions of causality in a pair could imply a bidirectional relationship between most regions, or could alternatively imply a unidirectional forcing (synchrony) phenomenon. Sliding windows of 200 ms were used, with a sliding step of 50 ms. A library size of 80 was used.\relax }}{41}}
\newlabel{fig:diff_within_pair_hist}{{21}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-E}}Algorithms and Techniques}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-F}}Metrics and Benchmark}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-G}}Algorithms and Techniques}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Results}{44}}
\newlabel{fig:sample_pair_causality_plot}{{22a}{45}}
\newlabel{sub@fig:sample_pair_causality_plot}{{a}{45}}
\newlabel{fig:sample_size_diff_box}{{22b}{45}}
\newlabel{sub@fig:sample_size_diff_box}{{b}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces (a) A sample graph plotting the convergent cross mapping skill ($\rho $) between region 1 and 2 during the first 200 ms of the experiment. The skill mapping channel 1 to channel 2 is very similar to the one mapping channel 2 to channel 1. This might infer either bidirectional causality or unidirectional forcing. A similar pattern (close $\rho $ value between pairs) was found for most of the pairs. Cross mapping was done with random library samples. (b) Difference of rho scores between shown sample size and 100 samples. Decreasing sample size from the default 100 when calculating Sugihara Causality does not have a drastic affect on the acquired result. This shows that the data and method used are robust. Using this analysis, we conduct all further tests on a sample size of 20. Data shown is from the first 5 seconds of the experiment, using a library size of 80. Sliding windows of 200 ms were used, with a sliding step of 50 ms.\relax }}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces The distribution of CCM skill ($\rho $) during the entire experiment. Many relationships appear to be causal in the brain, with equally as many being non-causal throughout the experiment. Causality was calculated from signals of lumped regions after calculating the CSD. Cross mapping was done on every pair of regions with library size of 80, and each pair has two causality directions. Sliding windows of 200 ms were used, with a sliding step of 50 ms.\relax }}{46}}
\newlabel{fig:rho_hist_all_experiment}{{23}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Difference of causality values within a pair is small, even when accounting for non-existing relationships where both causalities are below 0.2. This similarity between directions of causality in a pair could imply a bidirectional relationship between most regions, or could alternatively imply a unidirectional forcing (synchrony) phenomenon. Sliding windows of 200 ms were used, with a sliding step of 50 ms. A library size of 80 was used.\relax }}{46}}
\newlabel{fig:diff_within_pair_hist}{{24}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Principle Component Analysis conducted on the three datasets reveals that the overall variance of the data can be maintained by using only a subset of the edges of the graph rather than all of them. The dataset with a time step of 250 ms needs less components to explain the variance than the other two, while the datasets with 200 and 50 ms time steps showed an almost exact level of variance explained with the number of components. This suggests that the 250 ms dataset is not complex enough, which might indicate that 2000 ms is too big of a time frame to record the granular communication speed of the brain.\relax }}{47}}
\newlabel{fig:pca_analysis_variance}{{25}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Different component numbers are needed for each dataset to maintain a certain level of variance explained using PCA for dimensionality reduction. These values for components required for reaching a score standard were used to produce reduced forms of the datasets. These reduced forms of the datasets were then analyzed in figure 26\hbox {}.\relax }}{47}}
\newlabel{tab:components_needed_for_variance}{{III}{47}}
\citation{Ye2015}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Silhouette scores for clustering with different cluster numbers. The score dips greatly when creating more than two clusters, but begins to rise after \nobreakspace  {}30 clusters. The silhouette scores show that having more components when reducing with PCA results in better clustering scores. The scores also show that scores for the reduced data that keep 99\% of the variance (right column) are all similar in score and trend.\relax }}{48}}
\newlabel{fig:silhouette_scores}{{26}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Discussion}{48}}
\citation{Ye2015}
\citation{Lewis2012}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Future Work}{49}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,main.bib}
\bibcite{RobSchapire}{1}
\@writefile{toc}{\contentsline {section}{\numberline {X}Conclusion}{50}}
\bibcite{assael2016lipnet}{2}
\bibcite{Lucas20016}{3}
\bibcite{tompson2016accelerating}{4}
\bibcite{Iwana2016}{5}
\bibcite{practicalDefEpi2014}{6}
\bibcite{Epilepsy.com.NewTerms}{7}
\bibcite{Epilepsy.com.stats}{8}
\bibcite{Allers2015}{9}
\bibcite{vivas2012health}{10}
\bibcite{AEDsideeffects}{11}
\bibcite{Epilepsy.com.surgery}{12}
\bibcite{bailey2005use}{13}
\bibcite{baranano2008ketogenic}{14}
\bibcite{britanica1i2016}{15}
\bibcite{mcculloch1943logical}{16}
\bibcite{minsky1969perceptrons}{17}
\bibcite{Yadav2015}{18}
\bibcite{mitchell1997machine}{19}
\bibcite{Finney1996}{20}
\bibcite{Locke1841}{21}
\bibcite{Berkeley1874}{22}
\bibcite{Granger1969}{23}
\bibcite{Sugihara2012}{24}
\bibcite{lorenz1963deterministic}{25}
\@writefile{toc}{\contentsline {section}{References}{51}}
\bibcite{Dixon1999}{26}
\bibcite{Deyle2011}{27}
\bibcite{Takens1981}{28}
\bibcite{TakensYoutube2012}{29}
\bibcite{Deyle16042013}{30}
\bibcite{Wang2014}{31}
\bibcite{Mcbride2015}{32}
\bibcite{Nes2015}{33}
\bibcite{Tsonis2015}{34}
\bibcite{Mccracken2014}{35}
\bibcite{Clark2015}{36}
\bibcite{wismuller2014}{37}
\bibcite{hjornevik2007}{38}
\bibcite{paxinos2009}{39}
\bibcite{Potworowski2012}{40}
\bibcite{Ye2015}{41}
\bibcite{Lewis2012}{42}
